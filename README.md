Here's a detailed documentation guide for your chatbot project, focusing on the key areas outlined in your task details:

---

# AI Chatbot Documentation

## Overview

This AI chatbot provides responses based on lecture notes from an AI course, utilizing OpenAI's API and LangChain for document management and vector storage. The application integrates a user-friendly web interface using Gradio for user interaction.

---

## 1. **Document Ingestion and Storage**

The chatbot uses **LangChain** to manage AI lecture notes. These lecture notes are ingested from PDFs, processed to extract text, and then stored in a vector database for fast retrieval and query-based responses.

### Steps:

1. **Download Lecture Notes**:

   - Use the `download_lecture_notes` function to fetch the lecture PDFs.
   - Example code:
     ```python
     from document_loader import download_lecture_notes
     documents = download_lecture_notes()
     ```

2. **Process PDFs**:

   - The `process_documents` function extracts text from the PDF files using **PyMuPDF**.
   - Example code:
     ```python
     from document_processor import process_documents
     texts = process_documents(documents)
     ```

3. **Generate Embeddings**:

   - The texts are transformed into embeddings using OpenAI's `text-embedding-ada-002` model.
   - Example code:
     ```python
     from embeddings import generate_embeddings
     embeddings = generate_embeddings(texts)
     ```

4. **Store Embeddings in Chroma**:
   - The embeddings and their corresponding texts are stored in **ChromaDB**, a vector database, to enable quick retrieval during queries.
   - Example code:
     ```python
     from chroma_storage import store_embeddings_in_chroma
     store_embeddings_in_chroma(texts, embeddings)
     ```

### Notes:

- ChromaDB stores embeddings in a collection called `lecture_notes`.
- Each document is assigned a unique ID using `uuid`.

---

## 2. **OpenAI Integration**

The chatbot uses **OpenAI's API** to generate answers based on retrieved document embeddings. The chatbot logic combines retrieved documents with a user query to generate a coherent response.

### Key Steps:

1. **Embedding Generation**:

   - When a user inputs a query, the system generates an embedding for the query using OpenAIâ€™s `text-embedding-ada-002`.
   - Example code:
     ```python
     response = openai.embeddings.create(input=query, model="text-embedding-ada-002")
     ```

2. **Document Retrieval**:

   - The system performs a similarity search in the vector database using the query embedding to find the most relevant documents.
   - Example code:
     ```python
     relevant_docs = collection.query(query_embeddings=[query_embedding], n_results=3)
     ```

3. **Generate Response**:
   - The retrieved documents and the query are fed into OpenAI's **Chat Completion** API to generate a response.
   - Example code:
     ```python
     response = client.chat.completions.create(
         model="gpt-3.5-turbo",
         messages=[
             {"role": "system", "content": "You are a helpful assistant..."},
             {"role": "user", "content": f"Context: {context}\n\nQuestion: {query}"}
         ]
     )
     ```

### References:

- **[Quickstart Guide](https://platform.openai.com/docs/quickstart)**: Overview of OpenAI API usage.
- **[Chat Completions Guide](https://platform.openai.com/docs/guides/chat-completions)**: Learn more about the chat completion feature.

---

## 3. **Web Interface Development**

The chatbot uses **Gradio** to build an interactive, easy-to-use interface for users to ask questions based on the lecture notes.

### Key Steps:

1. **Define Chatbot Interface**:

   - The Gradio interface is defined in `web_app.py` and connects to the chatbot logic.
   - Example code:
     ```python
     iface = gr.Interface(
         fn=chatbot_interface,
         inputs="text",
         outputs="text",
         title="AI Teaching Assistant",
         description="Ask questions about AI lecture notes!"
     )
     ```

2. **Run Gradio Application**:
   - To launch the chatbot interface:
     ```python
     if __name__ == "__main__":
         iface.launch()
     ```

### Features:

- The Gradio interface allows users to input questions in a text box and receive responses generated by the chatbot based on AI lecture notes.
- Customizable components, such as buttons, text boxes, and labels, can be added as needed.

### Reference:

- **[Gradio Documentation](https://gradio.app/docs/)** for more details on customizing the UI.

---

## 4. **Testing**

Comprehensive testing has been done on individual components of the chatbot, ensuring robust functionality.

### Key Test Files:

- **`test_chatbot.py`**: Tests chatbot responses to user queries.
- **`test_embeddings.py`**: Tests the embedding generation and storage process.
- **`test_langchain.py`**: Tests the document ingestion and query workflow.
- **`test_openai_key.py`**: Verifies the OpenAI API key and connection.

### Example Test:

- To run a chatbot query test:
  ```bash
  python src/test_chatbot.py
  ```

### Reference:

- For further details, explore the testing scripts in the `src/` folder.

---

## 5. **Deployment and Documentation**

### Deployment Instructions:

1. **Clone the Repository**:

   ```bash
   git clone https://github.com/....git
   ```

2. **Install Dependencies**:
   Ensure you have Python and `pip` installed. Then, install the required packages:

   ```bash
   pip install -r requirements.txt
   ```

3. **Set Up Environment Variables**:

   - Create a `.env` file in the root directory:
     ```
     OPENAI_API_KEY=your_openai_api_key
     ```

4. **Run the Chatbot**:
   Start the Gradio-based chatbot interface:

   ```bash
   python src/web_app.py
   ```

5. **Deploying to a Cloud Service**:
   - You can deploy the application using services like **Heroku**, **AWS**, or **DigitalOcean**.
   - Make sure the `.env` file is correctly set up in the cloud environment.

---

## 6. **References and Further Learning**

- **OpenAI**:
  - [OpenAI Quickstart](https://platform.openai.com/docs/quickstart)
  - [Chat Completions Guide](https://platform.openai.com/docs/guides/chat-completions)
  - [Prompt Engineering Guide](https://platform.openai.com/docs/guides/prompt-engineering)
- **LangChain**:
  - [LangChain Tutorial](https://python.langchain.com/docs/tutorials/chatbot)
  - [RAG Applications](https://python.langchain.com/docs/tutorials/rag)

---

This documentation should guide both developers and users through setting up and understanding your chatbot system. For continuous improvements or scaling, additional adjustments to performance metrics or the vector storage system might be needed, but this should serve as a comprehensive overview for now.
